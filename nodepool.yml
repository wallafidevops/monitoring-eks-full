apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: monitoring
spec:
  role: "KarpenterNodeRole-cluster-prd" # replace with your cluster name
  amiSelectorTerms:
    - alias: "al2023@latest"
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "cluster-prd" # replace with your cluster name
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "cluster-prd"
  tags:
    Name: prd-monitoring-v1
    monitoring: "true" 
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 30Gi          # ✔️ Tamanho do root volume
        volumeType: gp3           # ✔️ Tipo do volume
        encrypted: true           # ✔️ Sempre recomendo
        deleteOnTermination: true            
  metadataOptions:
    httpEndpoint: enabled
    httpProtocolIPv6: disabled
    httpPutResponseHopLimit: 2
    httpTokens: required  
---

apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: monitoring
spec:
  limits:
    cpu: 6
    memory: 32Gi
  template:
    spec:
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: kubernetes.io/os
          operator: In
          values: ["linux"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["t"]
        # - key: karpenter.k8s.aws/instance-generation
        #   operator: Gt
        #   values: ["2"]
        - key: monitoring
          operator: In
          values: ["true"]
      taints:
        - key: "monitoring"
          value: "true"
          effect: "NoSchedule"
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: monitoring
      expireAfter: 720h # 30 * 24h = 720h
  # limits:
  #   cpu: 1000
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 1m